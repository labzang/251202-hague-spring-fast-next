"""
NLTK ìì—°ì–´ ì²˜ë¦¬ ì„œë¹„ìŠ¤
NLTK(Natural Language Toolkit) íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ë° ë¬¸ì„œ ë¶„ì„ ì„œë¹„ìŠ¤

ì£¼ìš” ê¸°ëŠ¥:
- ë§ë­‰ì¹˜ ê´€ë¦¬
- í† í° ìƒì„±
- í˜•íƒœì†Œ ë¶„ì„
- í’ˆì‚¬ íƒœê¹…
- í…ìŠ¤íŠ¸ ë¶„ì„
- ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
"""

import re
import pandas as pd

import matplotlib.pyplot as plt


from nltk import FreqDist
from wordcloud import WordCloud
import logging
from konlpy.tag import Okt

logger = logging.getLogger(__name__)


class SamsungWordcloud:
    
    def __init__(self):
        self.okt = Okt()

    def text_process(self):
        freq_txt = self.find_freq()
        file_info = self.draw_wordcloud()
        return {
            'ì „ì²˜ë¦¬ ê²°ê³¼': 'ì™„ë£Œ',
            'freq_txt': freq_txt,
            'saved_file': file_info
        }
        
    def read_file(self):
        self.okt.pos("ì‚¼ì„±ì „ì ê¸€ë¡œë²Œì„¼í„° ì „ìì‚¬ì—…ë¶€" , stem=True)
        fname = 'app/nlp/data/kr-Report_2018.txt'
        with open(fname, 'r', encoding='utf-8') as f:
            text = f.read()
        return text

    def extract_hangeul(self, text: str):
        temp = text.replace('\n', ' ')
        tokenizer = re.compile(r'[^ ã„±-í£]+')
        return tokenizer.sub('',temp)

    def change_token(self, texts):
        return word_tokenize(texts)
    
    def extract_noun(self):
        # ì‚¼ì„±ì „ìì˜ ìŠ¤ë§ˆíŠ¸í°ì€ -> ì‚¼ì„±ì „ì ìŠ¤ë§ˆíŠ¸í°
        noun_tokens = []
        tokens = self.change_token(self.extract_hangeul(self.read_file()))
        for i in tokens:
            pos = self.okt.pos(i)
            temp = [j[0] for j in pos if j[1] == 'Noun']
            if len(''.join(temp)) > 1 :
                noun_tokens.append(''.join(temp))
        texts = ' '.join(noun_tokens)
        logger.info(texts[:100])
        return texts

    def read_stopword(self):
        self.okt.pos("ì‚¼ì„±ì „ì ê¸€ë¡œë²Œì„¼í„° ì „ìì‚¬ì—…ë¶€", stem=True)
        fname = 'app/nlp/data/stopwords.txt'
        with open(fname, 'r', encoding='utf-8') as f:
            stopwords = f.read()
        return stopwords

    def remove_stopword(self):
        texts = self.extract_noun()
        tokens = self.change_token(texts)
        # print('------- 1 ëª…ì‚¬ -------')
        # print(texts[:30])
        stopwords = self.read_stopword()
        # print('------- 2 ìŠ¤í†± -------')
        # print(stopwords[:30])
        # print('------- 3 í•„í„° -------')
        texts = [text for text in tokens
                 if text not in stopwords]
        # print(texts[:30])
        return texts

    def find_freq(self):
        texts = self.remove_stopword()
        freqtxt = pd.Series(dict(FreqDist(texts))).sort_values(ascending=False)
        logger.info(freqtxt[:30])
        return freqtxt

    def draw_wordcloud(self, save_to_file=True):
        from pathlib import Path
        from datetime import datetime
        
        texts = self.remove_stopword()
        # D2Coding í°íŠ¸ë¥¼ ì‚¬ìš©í•œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (í•œê¸€ ì§€ì›)
        font_path = 'app/nlp/data/D2Coding.ttf'
        wcloud = WordCloud(font_path=font_path, relative_scaling=0.2, background_color='white', 
                           width=1200, height=800, max_words=100).generate(" ".join(texts))
        plt.figure(figsize=(12, 12))
        plt.imshow(wcloud, interpolation='bilinear')
        plt.axis('off')
        
        # save í´ë”ì— ì´ë¯¸ì§€ ì €ì¥
        if save_to_file:
            # save ë””ë ‰í† ë¦¬ ìƒì„±
            save_dir = Path("app/nlp/samsung/save")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"samsung_wordcloud_{timestamp}.png"
            save_path = save_dir / filename
            
            # ì´ë¯¸ì§€ ì €ì¥
            plt.savefig(save_path, dpi=300, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            logger.info(f"ğŸ¨ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
            
            # íŒŒì¼ ì •ë³´ ë°˜í™˜ìš©
            file_info = {
                "filename": filename,
                "path": str(save_path),
                "size_bytes": save_path.stat().st_size if save_path.exists() else 0,
                "exists": save_path.exists()
            }
            
            plt.show()
            return file_info
        else:
            plt.show()
            return None